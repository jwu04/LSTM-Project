{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a996f80c",
   "metadata": {},
   "source": [
    "# Using LSTMs to Predict LeBron James' Points in the Next Game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4205f798",
   "metadata": {},
   "source": [
    "**Team:** Taiyo Nakai & Jonathan Wu  \n",
    "**Objective:** Train an LSTM neural network to predict LeBron James' performance (e.g., over/under betting) using historical game data.  \n",
    "**Methods:** LSTM model with softmax activation for multiclass outcomes. Incorporating long-term and short-term performance trends.  \n",
    "**Data Source:** Basketball Reference (https://www.basketball-reference.com/players/j/jamesle01.html); CSV files for individual player game data  \n",
    "**Evaluation:** Precision-based evaluation with every game betting simulation.  \n",
    "**Experiments:** Hyperparameter tuning for LSTM architecture, dropout, and forget gate bias initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aa092c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2929266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "from io import StringIO\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sortedcontainers import SortedSet\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025d1257",
   "metadata": {},
   "source": [
    "# Loading and Merging LeBron James Game Logs\n",
    "\n",
    "This code loads and combines multiple CSV files containing LeBron James' game logs from a specified folder.  \n",
    "1. Recursively searches for CSV files in the `GAME_LOG_FOLDER`.  \n",
    "2. Adds each file path to a sorted set to maintain the ordered date.  \n",
    "3. Reads and concatenates all CSV files into a single DataFrame `df`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f8dad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>G</th>\n",
       "      <th>Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Opp</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>...</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>GmSc</th>\n",
       "      <th>+/-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/29/2003</td>\n",
       "      <td>18-303</td>\n",
       "      <td>CLE</td>\n",
       "      <td>@</td>\n",
       "      <td>SAC</td>\n",
       "      <td>L (-14)</td>\n",
       "      <td>1</td>\n",
       "      <td>42:50:00</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>24.7</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10/30/2003</td>\n",
       "      <td>18-304</td>\n",
       "      <td>CLE</td>\n",
       "      <td>@</td>\n",
       "      <td>PHO</td>\n",
       "      <td>L (-9)</td>\n",
       "      <td>1</td>\n",
       "      <td>40:21:00</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>14.7</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11/1/2003</td>\n",
       "      <td>18-306</td>\n",
       "      <td>CLE</td>\n",
       "      <td>@</td>\n",
       "      <td>POR</td>\n",
       "      <td>L (-19)</td>\n",
       "      <td>1</td>\n",
       "      <td>39:10:00</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11/5/2003</td>\n",
       "      <td>18-310</td>\n",
       "      <td>CLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>L (-4)</td>\n",
       "      <td>1</td>\n",
       "      <td>41:06:00</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>11.2</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11/7/2003</td>\n",
       "      <td>18-312</td>\n",
       "      <td>CLE</td>\n",
       "      <td>@</td>\n",
       "      <td>IND</td>\n",
       "      <td>L (-1)</td>\n",
       "      <td>1</td>\n",
       "      <td>43:44:00</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>78</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4/6/2025</td>\n",
       "      <td>40-098</td>\n",
       "      <td>LAL</td>\n",
       "      <td>@</td>\n",
       "      <td>OKC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>79</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4/8/2025</td>\n",
       "      <td>40-100</td>\n",
       "      <td>LAL</td>\n",
       "      <td>@</td>\n",
       "      <td>OKC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>80</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4/9/2025</td>\n",
       "      <td>40-101</td>\n",
       "      <td>LAL</td>\n",
       "      <td>@</td>\n",
       "      <td>DAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>81</td>\n",
       "      <td>81.0</td>\n",
       "      <td>4/11/2025</td>\n",
       "      <td>40-103</td>\n",
       "      <td>LAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>82</td>\n",
       "      <td>82.0</td>\n",
       "      <td>4/13/2025</td>\n",
       "      <td>40-105</td>\n",
       "      <td>LAL</td>\n",
       "      <td>@</td>\n",
       "      <td>POR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1767 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rk     G        Date     Age   Tm Unnamed: 5  Opp Unnamed: 7   GS  \\\n",
       "0      1   1.0  10/29/2003  18-303  CLE          @  SAC    L (-14)    1   \n",
       "1      2   2.0  10/30/2003  18-304  CLE          @  PHO     L (-9)    1   \n",
       "2      3   3.0   11/1/2003  18-306  CLE          @  POR    L (-19)    1   \n",
       "3      4   4.0   11/5/2003  18-310  CLE        NaN  DEN     L (-4)    1   \n",
       "4      5   5.0   11/7/2003  18-312  CLE          @  IND     L (-1)    1   \n",
       "...   ..   ...         ...     ...  ...        ...  ...        ...  ...   \n",
       "1762  78  78.0    4/6/2025  40-098  LAL          @  OKC        NaN  NaN   \n",
       "1763  79  79.0    4/8/2025  40-100  LAL          @  OKC        NaN  NaN   \n",
       "1764  80  80.0    4/9/2025  40-101  LAL          @  DAL        NaN  NaN   \n",
       "1765  81  81.0   4/11/2025  40-103  LAL        NaN  HOU        NaN  NaN   \n",
       "1766  82  82.0   4/13/2025  40-105  LAL          @  POR        NaN  NaN   \n",
       "\n",
       "            MP  ...  DRB  TRB  AST  STL  BLK  TOV   PF PTS  GmSc  +/-  \n",
       "0     42:50:00  ...    4    6    9    4    0    2    3  25  24.7   -9  \n",
       "1     40:21:00  ...   10   12    8    1    0    7    1  21  14.7   -3  \n",
       "2     39:10:00  ...    4    4    6    2    0    2    3   8     5  -21  \n",
       "3     41:06:00  ...    9   11    7    2    3    2    1   7  11.2   -3  \n",
       "4     43:44:00  ...    5    5    3    0    0    7    2  23     9   -7  \n",
       "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ..   ...  ...  \n",
       "1762       NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  -1   NaN  NaN  \n",
       "1763       NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  -1   NaN  NaN  \n",
       "1764       NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  -1   NaN  NaN  \n",
       "1765       NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  -1   NaN  NaN  \n",
       "1766       NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  -1   NaN  NaN  \n",
       "\n",
       "[1767 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAME_LOG_FOLDER = \"LeBron James Game Logs\"\n",
    "\n",
    "def fetch_files(DIRECTORY=\"LeBron James Game Logs\"):\n",
    "    csv_files = SortedSet()\n",
    "    for dir_, _, files in os.walk(DIRECTORY):\n",
    "        for file_name in files:\n",
    "            rel_dir = os.path.relpath(dir_, DIRECTORY)\n",
    "            rel_file = os.path.join(DIRECTORY, file_name)\n",
    "            csv_files.add(rel_file)\n",
    "\n",
    "    df = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
    "    return df\n",
    "    \n",
    "df = fetch_files()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90fa4fb",
   "metadata": {},
   "source": [
    "# Renaming Columns in Game Log Data\n",
    "\n",
    "This code renames two in the game log DataFrame for better readability.  \n",
    "\n",
    "1. Renames the columns `'Unnamed: 5'` and `'Unnamed: 7'` to `'Location'` and `'Score Differential'`, respectively.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e45587a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rk', 'G', 'Date', 'Age', 'Tm', 'Location', 'Opp',\n",
       "       'Score Differential', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA',\n",
       "       '3P%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL',\n",
       "       'BLK', 'TOV', 'PF', 'PTS', 'GmSc', '+/-'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retain the original df before editing\n",
    "original_df = df.copy()\n",
    "\n",
    "def df_rename(df):\n",
    "    df = df.rename(columns={'Unnamed: 5': 'Location', 'Unnamed: 7': 'Score Differential'})\n",
    "    return df\n",
    "\n",
    "df = df_rename(df)\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cac6fe",
   "metadata": {},
   "source": [
    "# Data Cleaning & Feature Engineering\n",
    "\n",
    "This code performs several data preprocessing steps on the game log DataFrame to clean.  \n",
    "1. Drops rows where the `'G'` (Game) column is NaN.  \n",
    "2. Converts the `'Date'` column to datetime format, and extracts the day, month, and year into new columns.  \n",
    "3. Drops irrelevant columns like `'Rk'`, `'G'`, `'Date'`, etc.  \n",
    "4. Maps categorical values in the `'Location'` column (home or away) and updates `'Opp'` and `'Tm'` columns to numeric values representing teams.  \n",
    "5. Converts the `'MP'` column (minutes played) into a float, representing total minutes played in decimal format.  \n",
    "6. Calculates and updates the `'Age'` column by converting it from a year-day format to a float representing age in years.  \n",
    "7. Converts all columns to `float` type for consistency.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81d0dca1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Location</th>\n",
       "      <th>Opp</th>\n",
       "      <th>PTS</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.830137</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.832877</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.838356</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.849315</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.854795</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>40.268493</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>40.273973</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>40.276712</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>40.282192</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>40.287671</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2025.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1574 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age    Tm  Location   Opp   PTS   Day  Month    Year\n",
       "0     18.830137   6.0       1.0  26.0  25.0  29.0   10.0  2003.0\n",
       "1     18.832877   6.0       1.0  24.0  21.0  30.0   10.0  2003.0\n",
       "2     18.838356   6.0       1.0  25.0   8.0   1.0   11.0  2003.0\n",
       "3     18.849315   6.0       0.0   8.0   7.0   5.0   11.0  2003.0\n",
       "4     18.854795   6.0       1.0  12.0  23.0   7.0   11.0  2003.0\n",
       "...         ...   ...       ...   ...   ...   ...    ...     ...\n",
       "1762  40.268493  14.0       1.0  21.0  -1.0   6.0    4.0  2025.0\n",
       "1763  40.273973  14.0       1.0  21.0  -1.0   8.0    4.0  2025.0\n",
       "1764  40.276712  14.0       1.0   7.0  -1.0   9.0    4.0  2025.0\n",
       "1765  40.282192  14.0       0.0  11.0  -1.0  11.0    4.0  2025.0\n",
       "1766  40.287671  14.0       1.0  25.0  -1.0  13.0    4.0  2025.0\n",
       "\n",
       "[1574 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleansing(df):\n",
    "    df.drop(df.index[df['G'].isnull()], inplace = True)\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Day'] = df['Date'].dt.day\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "\n",
    "    df = df.drop(columns=['Rk', 'G', 'Date', 'Score Differential', 'GS', 'GmSc', '+/-', 'ORB', 'DRB', 'TRB', \n",
    "                          'AST', 'STL', 'BLK', 'TOV', 'PF', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA',\n",
    "                          '3P%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL',\n",
    "                          'BLK', 'TOV', 'PF'])\n",
    "\n",
    "    df['Location'] = df['Location'].map({'@': 1, np.nan: 0}) \n",
    "\n",
    "    df['Opp'] = df['Opp'].map({'ATL': 1, 'BOS': 2, 'BRK': 3, 'NJN': 3, 'CHA': 4, 'CHO': 4,\n",
    "                               'CHI': 5, 'CLE': 6, 'DAL': 7, 'DEN': 8, 'DET': 9, 'GSW': 10, \n",
    "                               'HOU': 11, 'IND': 12, 'LAC': 13, 'LAL': 14, 'MEM': 15, 'MIA': 16, \n",
    "                               'MIL': 17, 'MIN': 18, 'NOH': 19, 'NOK': 19, 'NOP': 19, 'NYK': 20, \n",
    "                               'OKC': 21, 'ORL': 22, 'PHI': 23, 'PHO': 24, 'POR': 25, 'SAC': 26,\n",
    "                               'SAS': 27, 'SEA': 28, 'TOR': 29, 'UTA': 30, 'WAS': 31}) \n",
    "\n",
    "    df['Tm'] = df['Tm'].map({'ATL': 1, 'BOS': 2, 'BRK': 3, 'NJN': 3, 'CHA': 4, 'CHO': 4,\n",
    "                             'CHI': 5, 'CLE': 6, 'DAL': 7, 'DEN': 8, 'DET': 9, 'GSW': 10, \n",
    "                             'HOU': 11, 'IND': 12, 'LAC': 13, 'LAL': 14, 'MEM': 15, 'MIA': 16, \n",
    "                             'MIL': 17, 'MIN': 18, 'NOH': 19, 'NOK': 19, 'NOP': 19, 'NYK': 20, \n",
    "                             'OKC': 21, 'ORL': 22, 'PHI': 23, 'PHO': 24, 'POR': 25, 'SAC': 26,\n",
    "                             'SAS': 27, 'SEA': 28, 'TOR': 29, 'UTA': 30, 'WAS': 31})\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        year, days = df.loc[i]['Age'].split('-')\n",
    "        if int(df.loc[i]['Year']) % 4 == 0:\n",
    "            days = int(days) / 366\n",
    "        else:\n",
    "            days = int(days) / 365\n",
    "        df.loc[i, 'Age'] = int(year) + days\n",
    "\n",
    "    df = df.astype(float)\n",
    "    return df\n",
    "\n",
    "df = cleansing(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405dbdfe",
   "metadata": {},
   "source": [
    "# Data Scaling and Splitting for Time-Series Model\n",
    "\n",
    "This code scales the features and target variable, and prepares the data for training a time-series model using sliding windows.   \n",
    "1. **Scaling:**  \n",
    "   - Scales the feature columns (excluding `'PTS'`) using `MinMaxScaler`.  \n",
    "   - Scales the target column `'PTS'` using the same scaler.  \n",
    "2. **Data Splitting:**  \n",
    "   - Defines a `split()` function that creates sequences of past data points (with a specified window length) to predict future values.  \n",
    "3. **Train/Test Split:**  \n",
    "   - Splits the scaled features into training (80%) and testing (20%) sets.  \n",
    "4. **Windowing:**  \n",
    "   - Applies the `split()` function to create input-output pairs for training and testing using a variable sliding window length.  \n",
    "5. **Reshaping:**  \n",
    "   - Reshapes the input data into 3D arrays suitable for feeding into a neural network (samples, time steps, features).  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3de473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 5\n",
    "YEAR_LIMIT = 2022\n",
    "\n",
    "def split_train_test(df, window, year_limit):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_features = scaler.fit_transform(df.drop(columns=['PTS']))\n",
    "    scaled_target = scaler.fit_transform(df[['PTS']])\n",
    "\n",
    "    def split(dataset, window=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-window-1):\n",
    "            a = dataset[i:(i+window), 0]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + window, 0])\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "\n",
    "    train_size = df[(df['Year'] < year_limit) | ((df['Year'] == year_limit) & (df['Month'] < 7))].shape[0]\n",
    "    test_size = len(scaled_target) - train_size\n",
    "    train, test = scaled_features[0:train_size,:], scaled_target[train_size:len(scaled_target),:]\n",
    "\n",
    "    trainX, trainY = split(train, window)\n",
    "    testX, testY = split(test, window)\n",
    "\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "    \n",
    "    return trainX, testX, trainY, testY, scaler\n",
    "\n",
    "trainX, testX, trainY, testY, scaler = split_train_test(df, WINDOW, YEAR_LIMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e91818",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for LSTM Model\n",
    "\n",
    "This code tunes the hyperparameters of an LSTM-based model for predicting LeBron James' points in future games.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14af62c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Tuning():\n",
    "    tuning_directory = 'LSTM_Tuning_Results'\n",
    "    if os.path.exists(tuning_directory):\n",
    "        shutil.rmtree(tuning_directory)\n",
    "    \n",
    "    def build_model(hp):\n",
    "        model = Sequential([\n",
    "            Input(shape=(trainX.shape[1], trainX.shape[2])),\n",
    "            Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(0.001))),\n",
    "            LSTM(64, return_sequences=True, kernel_regularizer=l2(0.001)),\n",
    "            Dropout(0.25),\n",
    "            LSTM(50,return_sequences=True),\n",
    "            Dropout(0.25),\n",
    "            LSTM(50,return_sequences=True),\n",
    "            Dropout(0.25),\n",
    "            LSTM(50),\n",
    "            Dropout(0.25),\n",
    "            Dense(48, kernel_regularizer=l2(0.001)),\n",
    "            Dense(1, kernel_regularizer=l2(0.001), bias_initializer='zeros')\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(\n",
    "                learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "            ),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    # Initialize the tuner\n",
    "    tuner = kt.Hyperband(\n",
    "        build_model,  # Model-building function\n",
    "        objective='val_mae',  # Optimize for validation MAE\n",
    "        max_epochs=50,  # Max epochs for training\n",
    "        factor=3,  # Reduction factor\n",
    "        directory=tuning_directory,\n",
    "        project_name='LSTM_Hyperband'\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(monitor='val_mae', patience=10)\n",
    "    ]\n",
    "\n",
    "    # Perform hyperparameter search\n",
    "    tuner.search(\n",
    "        trainX, trainY,\n",
    "        epochs=50,\n",
    "        validation_data=(testX, testY),\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    \n",
    "    # Build the best model\n",
    "    model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "    # Train the best model\n",
    "    model_History = model.fit(\n",
    "        trainX, trainY,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_data=(testX, testY),\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    return model, model_History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f0f942",
   "metadata": {},
   "source": [
    "# Building and Training the LSTM Model\n",
    "\n",
    "This code defines, compiles, and trains a LSTM model for predicting LeBron James' performance.  \n",
    "1. **Model Architecture:**  \n",
    "   - Creates a sequential model with the layers shown below\n",
    "2. **Compilation:**  \n",
    "   - Compiles the model using the Adam optimizer, mean squared error (MSE) loss, and mean absolute error (MAE) metric.  \n",
    "3. **Callbacks:**  \n",
    "   - Implements early stopping based on validation MAE with a patience of 10 epochs.  \n",
    "4. **Training:**  \n",
    "   - Trains the model for up to 100 epochs, using a batch size of 32, with validation data and the early stopping callback.  \n",
    "5. **Output:** The model's training history is stored in `LSTM_History`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98fc054",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 Complete [00h 00m 07s]\n",
      "val_mae: 0.19006116688251495\n",
      "\n",
      "Best val_mae So Far: 0.1813495010137558\n",
      "Total elapsed time: 00h 00m 49s\n",
      "\n",
      "Search: Running Trial #8\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.0013664         |0.00064118        |learning_rate\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "3                 |3                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "def build_LSTM(tuning=False):\n",
    "    if not tuning:\n",
    "        LSTM_Neurons = 128\n",
    "        dropout_val = 0.25\n",
    "        dense_neurons = 38\n",
    "        final_dense = 1\n",
    "        LSTM_Model = Sequential([\n",
    "            Input(shape=(trainX.shape[1], trainX.shape[2])),\n",
    "            \n",
    "            Bidirectional(LSTM(LSTM_Neurons, return_sequences=True, kernel_regularizer=l2(0.001))),\n",
    "            LSTM(LSTM_Neurons/2, return_sequences=True, kernel_regularizer=l2(0.001)),\n",
    "            Dropout(dropout_val),\n",
    "            LSTM(LSTM_Neurons/2,return_sequences=True),\n",
    "            Dropout(dropout_val),\n",
    "            LSTM(LSTM_Neurons/2,return_sequences=True),\n",
    "            Dropout(dropout_val),\n",
    "            LSTM(LSTM_Neurons/2),\n",
    "            Dropout(dropout_val),\n",
    "            Dense(dense_neurons, kernel_regularizer=l2(0.001)),\n",
    "            Dense(final_dense, kernel_regularizer=l2(0.001), bias_initializer='zeros')\n",
    "        ])\n",
    "\n",
    "        LSTM_Model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(monitor='val_mae', patience=10)\n",
    "        ]\n",
    "\n",
    "        LSTM_History = LSTM_Model.fit(trainX, trainY, epochs=100, batch_size=32, validation_data=(testX, testY), callbacks=callbacks)\n",
    "\n",
    "        return LSTM_Model, LSTM_History\n",
    "    else:\n",
    "        return LSTM_Tuning()\n",
    "\n",
    "LSTM, LSTM_History = build_LSTM(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd260e",
   "metadata": {},
   "source": [
    "# Evaluating and Making Predictions with the LSTM Model\n",
    "\n",
    "This code performs recurrent predictions using an LSTM model, updating test data with noisy predictions to simulate variability in the forecast.\n",
    "\n",
    "### Functions:\n",
    "\n",
    "1. **`new_window(X_test, scaled_prediction)`**:\n",
    "    - **Purpose**: Updates the `X_test` data by replacing values in the windows containing `0` with the given `scaled_prediction` value.\n",
    "    - Iterates over `X_test`, and if a window contains `0`, it replaces the `0` with `scaled_prediction`, decreasing the `replacement_index` until all applicable values are replaced.\n",
    "\n",
    "2. **`new_target(y_test, scaled_prediction)`**:\n",
    "    - **Purpose**: Updates the `y_test` target values by replacing the first occurrence of `0` with `scaled_prediction`.\n",
    "    - Finds the first `0` in `y_test` and replaces it with `scaled_prediction`.\n",
    "\n",
    "3. **`predict_with_noise(prediction)`**:\n",
    "    - **Purpose**: Adjusts a given prediction by adding noise based on statistical properties of historical data (`PTS`).\n",
    "    - Generates noise from a normal distribution based on the mean and standard deviation of the `PTS` column in `df`. If the noise is greater than the prediction, it averages the prediction with the noise; otherwise, it takes one-third of the average of both values to introduce more uncertainty.\n",
    "\n",
    "4. **`recurrent_predictions(X_test, y_test, current_length)`**:\n",
    "    - **Purpose**: Makes recurrent predictions with the LSTM model, updates the `PTS` column of a dataframe, and modifies the test data (`X_test`, `y_test`) based on the predictions.\n",
    "    - Predicts future values using the LSTM model and inverse scales the predictions.\n",
    "    - The prediction is adjusted with noise by calling `predict_with_noise()`.\n",
    "    - Updates `X_test` and `y_test` by calling `new_window()` and `new_target()` with the updated prediction.\n",
    "    - Repeats this process until all values are predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b05952",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def LSTM_Predict(year_limit):\n",
    "    def new_window(X_test, scaled_prediction):\n",
    "        \"\"\"\n",
    "        Updates the windows in the test data (X_test) by replacing the first occurrence of 0 \n",
    "        with the scaled prediction value at the appropriate index.\n",
    "        \"\"\"\n",
    "        replacement_index = 4\n",
    "        for _ in X_test:\n",
    "            for window in _:\n",
    "                if 0 in window and replacement_index >= 0:\n",
    "                    window[replacement_index] = scaled_prediction.item()\n",
    "                    replacement_index -= 1\n",
    "                elif replacement_index < 0:\n",
    "                    break\n",
    "\n",
    "    def new_target(y_test, scaled_prediction):\n",
    "        \"\"\"\n",
    "        Updates the target values (y_test) by replacing the first occurrence of 0 with the \n",
    "        scaled prediction value.\n",
    "        \"\"\"\n",
    "        index = np.where(y_test == 0)[0][0]\n",
    "        y_test[index] = scaled_prediction.item()\n",
    "\n",
    "    def predict_with_noise(prediction):\n",
    "        \"\"\"\n",
    "        Adds noise to the given prediction by drawing from a normal distribution based on \n",
    "        historical data statistics (mean and std of 'PTS'). The noisy prediction is adjusted \n",
    "        depending on whether the noise is greater than the original prediction.\n",
    "        \"\"\"\n",
    "        stats = df[(df['Year'] < year_limit) | ((df['Year'] == year_limit) & (df['Month'] < 7))]['PTS'].describe()\n",
    "        noise = np.random.normal(loc=stats['mean'], scale=stats['std'], size=1)\n",
    "        if noise > prediction:\n",
    "            return np.round((prediction + noise) / 1.8, 0) # Decided on arbitrarily\n",
    "        else:\n",
    "            return np.round((prediction + noise) / 2.8, 0) # Decided on arbitrarily\n",
    "\n",
    "    def recurrent_predictions(X_test, y_test, current_length):\n",
    "        \"\"\"\n",
    "        Makes recursive predictions using the LSTM model, updating the 'PTS' column in the \n",
    "        DataFrame with noisy predictions at each step. The process continues until all test \n",
    "        data is used.\n",
    "        \"\"\"\n",
    "        n = len(X_test)\n",
    "\n",
    "        while current_length < n:\n",
    "            current_X, current_y = X_test[:current_length], y_test[:current_length-1]\n",
    "\n",
    "            predictions = LSTM.predict(np.array(current_X))\n",
    "            predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "            predictions = [round(points[0]) for points in predictions]\n",
    "            actual = scaler.inverse_transform(np.array(current_y).reshape(-1, 1))\n",
    "\n",
    "            index = df[df['PTS'] == -1].index[0]\n",
    "            df.loc[index, 'PTS'] = predict_with_noise(predictions[-1])\n",
    "\n",
    "            temp_scaling = scaler.fit_transform(df[['PTS']])\n",
    "            scaled_index = temp_scaling.tolist().index([0])-1\n",
    "            scaled_number = temp_scaling[scaled_index]\n",
    "\n",
    "            new_window(X_test, scaled_number)\n",
    "            new_target(y_test, scaled_number)\n",
    "\n",
    "            current_length += 1\n",
    "\n",
    "        return predictions, actual\n",
    "\n",
    "    original_length = testY.tolist().index(0) + 1\n",
    "    predictions, actual = recurrent_predictions(testX, testY, original_length)\n",
    "    \n",
    "    return predictions, actual, original_length\n",
    "\n",
    "predictions, actual, original_length = LSTM_Predict(YEAR_LIMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2571ee1",
   "metadata": {},
   "source": [
    "# Plotting Actual vs. Predicted Values\n",
    "\n",
    "This code visualizes the actual and predicted values of points scored for the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa07586",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(actual[:original_length-1], label='Actual', color='blue')\n",
    "plt.axvline(x=original_length-2, color='black', linestyle='--', label='Unplayed')\n",
    "plt.plot(predictions, label='Predicted', color='red')\n",
    "\n",
    "plt.title('Actual vs. Predicted NBA Points')\n",
    "plt.xlabel('Game (Most Recent From Left to Right)')\n",
    "plt.ylabel('Points')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafccc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(actual, label='Actual + Simulated', color='blue')\n",
    "plt.axvline(x=original_length-2, color='black', linestyle='--', label='Unplayed')\n",
    "plt.plot(predictions, label='Predicted', color='red')\n",
    "\n",
    "plt.title('Actual vs. Predicted NBA Points')\n",
    "plt.xlabel('Game (Most Recent From Left to Right)')\n",
    "plt.ylabel('Points')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b251da0",
   "metadata": {},
   "source": [
    "# True Metric: Evaluation on Betting (Prop) Lines\n",
    "While we did use MAE to best fit the model on LeBron James' historical data in points scored, we evaluted the ability of the model on a second metric: how many prop lines can it accurate hit and/or predict?\n",
    "\n",
    "To do this, we scraped data from FanDuel's historical prop lines for LeBron James from 2023 to the present and compared it the actual points he scored that day, and how many points our model predicts him to actually score.\n",
    "\n",
    "We want to maximize the amount of money earned if we were to truly bet on Lebron James."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0235d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bettinglinesdf = pd.read_csv(\"Betting_Lines_2024_2025\")\n",
    "bettinglines = np.array(bettinglinesdf[\"Line\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4cdfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_combined = predictions[-window-2:] + predictionstemp\n",
    "y_combined = np.array(data2024[\"PTS\"])\n",
    "plt.plot(y_combined, label='Actual', color='blue')\n",
    "plt.plot(predictions_combined, label='Predicted', color='red')\n",
    "plt.plot(bettinglines, label='Betting Line', color='goldenrod')\n",
    "\n",
    "plt.title('Actual vs Predicted Points by Lebron James, 2024-2025')\n",
    "plt.xlabel('Game (Most Recent From Left to Right)')\n",
    "plt.ylabel('Points')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39426859",
   "metadata": {},
   "source": [
    "# Betting in Different Ways\n",
    "We will retroactively \"bet\" on points scored by Lebron James in several different ways, and see if one works better than others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904fb0eb",
   "metadata": {},
   "source": [
    "## Preparation: Predicting the rest of December 2024 \n",
    "(as of December 4, the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c881fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datafall2024 = pd.read_csv(\"December_2024_data\")\n",
    "datafall2024.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a00d55d",
   "metadata": {},
   "source": [
    "## Baseline: Bet the Favorite Every Game\n",
    "If one simply bet on the favorite between over and under for every game, how would they have fared so far?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e161f418",
   "metadata": {},
   "outputs": [],
   "source": [
    "bettinglinesdf['Actual Points'] = np.array(data2024['PTS'])\n",
    "bettinglinesdf['Predicted Points'] = np.array(predictions_combined)\n",
    "bettinglinesdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9861f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spendings = []  # Use a list to collect spendings\n",
    "earnings = []   # Use a list to collect earnings\n",
    "\n",
    "for index, row in bettinglinesdf.iterrows():\n",
    "    # Assign variables based on columns\n",
    "    line = row['Line']\n",
    "    over = row['Over']\n",
    "    under = row['Under']\n",
    "    actual = row['Actual Points']\n",
    "    predicted = row['Predicted Points']\n",
    "\n",
    "    # Betting over\n",
    "    if over < under:\n",
    "        # Positive odds\n",
    "        if over > 0:\n",
    "            spendings.append(100)\n",
    "            if actual > line:\n",
    "                earnings.append(100 + over)\n",
    "            else:\n",
    "                earnings.append(0)  # Add 0 if no earnings\n",
    "        # Negative odds\n",
    "        elif over < 0:\n",
    "            spendings.append(-over)\n",
    "            if actual > line:\n",
    "                earnings.append(100 - over)\n",
    "            else:\n",
    "                earnings.append(0)  # Add 0 if no earnings\n",
    "    # Betting under\n",
    "    elif over > under:\n",
    "        if under > 0:\n",
    "            spendings.append(100)\n",
    "            if actual < line:\n",
    "                earnings.append(100 + under)\n",
    "            else:\n",
    "                earnings.append(0)  # Add 0 if no earnings\n",
    "        elif under < 0:\n",
    "            spendings.append(-under)\n",
    "            if actual < line:\n",
    "                earnings.append(100 - under)\n",
    "            else:\n",
    "                earnings.append(0)  # Add 0 if no earnings\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "spendings = np.array(spendings)\n",
    "earnings = np.array(earnings)\n",
    "\n",
    "# Calculate total spendings and earnings\n",
    "total_spendings = spendings.sum()\n",
    "total_earnings = earnings.sum()\n",
    "\n",
    "print(f\"We bet ${total_spendings} to earn ${total_earnings} \\n for a net profit of ${total_earnings - total_spendings} \\n or ${round((total_earnings - total_spendings)/len(spendings), 2)} per game\")\n",
    "d = {'spendings': spendings, 'earnings': earnings}\n",
    "pd.DataFrame(data=d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f5f7a",
   "metadata": {},
   "source": [
    "Evidently, a person that bet on the favorite every game lost money."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b7ae6b",
   "metadata": {},
   "source": [
    "## Method 1: Predicted vs. Betting Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb7038",
   "metadata": {},
   "outputs": [],
   "source": [
    "spendings = []  # Use a list to collect spendings\n",
    "earnings = []   # Use a list to collect earnings\n",
    "\n",
    "for index, row in bettinglinesdf.iterrows():\n",
    "    # Assign variables based on columns\n",
    "    line = row['Line']\n",
    "    over = row['Over']\n",
    "    under = row['Under']\n",
    "    actual = row['Actual Points']\n",
    "    predicted = row['Predicted Points']\n",
    "\n",
    "    # Betting over\n",
    "    if predicted > line:\n",
    "        # Positive odds\n",
    "        if over > 0:\n",
    "            spendings.append(100)\n",
    "            if actual > line:\n",
    "                earnings.append(100 + over)\n",
    "            else:\n",
    "                earnings.append(0)  # Add 0 if no earnings\n",
    "        # Negative odds\n",
    "        elif over < 0:\n",
    "            spendings.append(-over)\n",
    "            if actual > line:\n",
    "                earnings.append(100 - over)\n",
    "            else:\n",
    "                earnings.append(0)  # Add 0 if no earnings\n",
    "    # Betting under\n",
    "    elif predicted < line:\n",
    "        if under > 0:\n",
    "            spendings.append(100)\n",
    "            if actual < line:\n",
    "                earnings.append(100 + under)\n",
    "            else:\n",
    "                earnings.append(0)  # Add 0 if no earnings\n",
    "        elif under < 0:\n",
    "            spendings.append(-under)\n",
    "            if actual < line:\n",
    "                earnings.append(100 - under)\n",
    "            else:\n",
    "                earnings.append(0)  # Add 0 if no earnings\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "spendings = np.array(spendings)\n",
    "earnings = np.array(earnings)\n",
    "\n",
    "# Calculate total spendings and earnings\n",
    "total_spendings = spendings.sum()\n",
    "total_earnings = earnings.sum()\n",
    "\n",
    "print(f\"We bet ${total_spendings} to earn ${total_earnings} \\n for a net profit of ${total_earnings - total_spendings} \\n or ${round((total_earnings - total_spendings)/len(spendings), 2)} per game\")\n",
    "d = {'spendings': spendings, 'earnings': earnings}\n",
    "pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414b0b70",
   "metadata": {},
   "source": [
    "This ended up being a worse strategy than the baseline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
